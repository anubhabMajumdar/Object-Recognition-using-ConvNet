\documentclass{article} % For LaTeX2e
\usepackage{nips13submit_e,times}
\usepackage{hyperref}
\usepackage{url}
\usepackage{graphicx}
\usepackage{subfig}

\title{Object Recognition using CALTECH 256 Dataset}


\author{
Anubhab Majumdar \\
\texttt{amajumd@ncsu.edu} \\
\And
Toshal Phene \\
\texttt{tphene@ncsu.edu} \\
\AND
Shubham Munot \\
\texttt{samunot@ncsu.edu} \\
}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to \LaTeX{} to determine where to break
% the lines. Using \AND forces a linebreak at that point. So, if \LaTeX{}
% puts 3 of 4 authors names on the first line, and the last on the second
% line, try using \AND instead of \And before the third author name.

\newcommand{\fix}{\marginpar{FIX}}
\newcommand{\new}{\marginpar{NEW}}

\nipsfinalcopy % Uncomment for camera-ready version

\begin{document}


\maketitle


\section{Introduction}
Object recognition is a quintessential machine learning problem of modern times. It is difficult for machines to recognize a large variety of objects in different conditions of lighting, occlusion and skew. In recent years, this field has seen huge leaps with machines becoming adept at object recognition. In this project, we explore different approaches of tackling this problem

\par We are using the CALTECH 256 dataset \href{http://www.vision.caltech.edu/Image_Datasets/Caltech256/}{(link)} for object recognition \cite{caltech_dataset_paper}. The dataset has 256 unique categories of images. The number of samples in each category varies from 80 to over 200. This dataset is quite a standard dataset in the field of object recognition and has been been used in important research papers like \cite{knn_svm_paper}. Our goal is to train a machine learning algorithm using 80\% of the data and test using the remaining 20\%. We experimented on a small subset (4-5 categories) of the dataset. 

\par The experiments have been implemented using student version of MATLAB and python/tensorflow. Some of the less computationally intensive models are trained on personal computers, while the deep networks are trained on VCL servers.


\section{Methodology}

A typical classification system is shown in Fig.\ref{fig:basic_system}. The paper focuses on the machine learning block shown in Fig.\ref{fig:basic_system}. Different learning algorithms ranging from simple and lazy methods like KNN to deep convolution neural network is applied and results are compared for a comprehensive understanding of which method works better. The paper also tries to draw conclusion as to why certain methods work better than others. 

\begin{figure}[h]
\centering
\includegraphics[scale=0.3]{learning_algorithm_basic.png}
\caption{A typical prediction system}
\label{fig:basic_system}
\end{figure}

Before jumping into the algorithms applied, let's talk about the data itself. We have chosen the following 4 categories for our experimentation:
\begin{itemize} 

\item
Backpack (Sample size - 151)
\item
Binoculars (Sample size - 216)
\item
Eiffel Tower (Sample size - 83)
\item
Fried egg (Sample size - 90)

\end{itemize}

Sample of some images from the dataset are shown in Fig.\ref{Fig:sample_dataset}.

\begin{figure}
\centering
\begin{tabular}{|c|c|c|c|}
\hline 
\subfloat{\includegraphics[scale = 0.05]{003_0001.jpg}} &
\subfloat{\includegraphics[scale = 0.05]{003_0002.jpg}} &
\subfloat{\includegraphics[scale = 0.05]{003_0003.jpg}} &
\subfloat{\includegraphics[scale = 0.05]{003_0004.jpg}}\\
\hline
\subfloat{\includegraphics[scale = 0.05]{012_0001.jpg}} &
\subfloat{\includegraphics[scale = 0.05]{012_0002.jpg}} &
\subfloat{\includegraphics[scale = 0.05]{012_0003.jpg}} &
\subfloat{\includegraphics[scale = 0.05]{012_0004.jpg}}\\
\hline 
\subfloat{\includegraphics[scale = 0.05]{062_0001.jpg}} &
\subfloat{\includegraphics[scale = 0.05]{062_0002.jpg}} &
\subfloat{\includegraphics[scale = 0.05]{062_0003.jpg}} &
\subfloat{\includegraphics[scale = 0.05]{062_0004.jpg}}\\
\hline 
\subfloat{\includegraphics[scale = 0.05]{078_0001.jpg}} &
\subfloat{\includegraphics[scale = 0.05]{078_0002.jpg}} &
\subfloat{\includegraphics[scale = 0.05]{078_0003.jpg}} &
\subfloat{\includegraphics[scale = 0.05]{078_0004.jpg}}\\
\hline

\end{tabular}
\caption{Few samples from our dataset}
\label{Fig:sample_dataset}
\end{figure}

\subsection{Baseline}


\subsection{KNN}
% write here

\subsection{SVM}
% write here


\subsection{Convolutional Neural Network}
Fully connected neural networks (NN) are not the most suitable architecture to classify images because such a network architecture does not take into account the spatial structure of the images. The spatial location information of individual pixels are lost as soon as we transform it's 2D structure to one dimension to input into the neural network architecture. To solve this problem, LeCunn et. al. came up with convolutional neural network (CNN). CNN is a deep NN architecture that retains the location information of training data and is well adapted to classify images. Also, since all layers of CNN are not completely connected, we can train them faster than a fully connected architecture. 
\par However, building and training a deep CNN architecture (CovNet) is not easy because:

\begin{itemize}
\item
There is no exact set of rules which determine how deep or how wide the network should be to produce good accuracy
\item
Small number of data samples per class in Caltech-256 dataset
\item
Huge computational cost of training a CovNet
\end{itemize}

There are 4 main aspects of CovNet that we need to determine:

\begin{itemize}
\item
Training data 
	\begin{itemize}
		\item
		How large the training set should be? Should the training set size be increased by augmenting the available images?
		\item
		What should be the resolution of each input image? 
		\item
		What should be the ideal batch size for training the network? 
	\end{itemize}	

\item
Convolutional layers
	\begin{itemize}
		\item
		What should be the depth of the network, i.e., how many convolutional layer should be present?
		\item
		What should be the width of the network, i.e., how many features should be present per convolutional layer?
	\end{itemize}

\item
Fully connected layer
	\begin{itemize}
		\item 
		What should be the size of the penultimate fully connected layer, i.e., how many neurons should it have?
	\end{itemize}

\item
Prevent overfitting - CNN, like NN can easily overfit. How to prevent that? 
\end{itemize} 

Our focus in this paper is more on trying to understand how tweaking each of the above mentioned aspect affects the performance of CovNet, rather than to try everything to somehow achieve good accuracy.
\par Since the number of samples per class is quite less, we decided to keep aside 20 samples from each class aside for test, and train our network with the remaining images. The batch size is kept 23 as there are 460 training images. We plan on staring with a simple 2 layer $\it{lean}$ model and tweak it's aspects in consecutive runs and determine the affects. The first network we trained has the following architecture:
\begin{itemize}
		\item 
		Input image resolution - 28x28
		\item
		Convolutional layer 1 - 32 features extracted using 5x5 local receptive field with max pooling applied to 2x2 regions. Activation function used is ReLU.
		\item
		Convolutional layer 2 - 64 features extracted using 5x5 local receptive field with max pooling applied to 2x2 regions. Activation function used is ReLU.
		\item
		A fully connected layer with 1024 neurons with ReLU activation function.
		\item
		The output layer has 4 neurons denoting the 4 classes. The output is determined using softmax cross entropy function.
				
\end{itemize}



\section{Experiments and Results}

\subsection{KNN}
% write here


\subsection{SVM}
% write here


\subsection{Convolutional Neural Network}



\section{Conclusion}




\begin{thebibliography}{9}

\bibitem{caltech_dataset_paper} 
Greg Griffin, Alex Holub and Pietro Perona. \\
\textit{Caltech-256 Object Category Dataset}. 
 
\bibitem{knn_svm_paper} 
Hao Zhang, Alexander C. Berg, Michael Maire and Jitendra Malik \\
\textit{SVM-KNN: Discriminative Nearest Neighbor Classification for Visual Category
Recognition}.

 
\bibitem{knuthwebsite} 
Knuth: Computers and Typesetting,
\\\texttt{http://www-cs-faculty.stanford.edu/\~{}uno/abcde.html}
\end{thebibliography}

\end{document}
